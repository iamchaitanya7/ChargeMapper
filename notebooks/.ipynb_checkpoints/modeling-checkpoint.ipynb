{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, balanced_accuracy_score\n",
    "from sklearn.utils import all_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set this to the root directory of the project\n",
    "path_root_dir=\"./\"\n",
    "data = pd.read_csv(path_root_dir+\"/data-science-Optimal-EV-station-placement/data/processed/all_city_data_with_pop.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>geometry</th>\n",
       "      <th>parking</th>\n",
       "      <th>edges</th>\n",
       "      <th>EV_stations</th>\n",
       "      <th>parking_space</th>\n",
       "      <th>civic</th>\n",
       "      <th>restaurant</th>\n",
       "      <th>park</th>\n",
       "      <th>...</th>\n",
       "      <th>cinema</th>\n",
       "      <th>library</th>\n",
       "      <th>commercial</th>\n",
       "      <th>retail</th>\n",
       "      <th>townhall</th>\n",
       "      <th>government</th>\n",
       "      <th>residential</th>\n",
       "      <th>city</th>\n",
       "      <th>population</th>\n",
       "      <th>Berlin_data_onlycenter_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>POLYGON ((8.4727605 50.099822499999995, 8.4730...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Frankfurt</td>\n",
       "      <td>9.014051</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>POLYGON ((8.4775730092433 50.10302720327834, 8...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Frankfurt</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>POLYGON ((8.479750879173663 50.09863320231676,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Frankfurt</td>\n",
       "      <td>9.014051</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>POLYGON ((8.479688060978736 50.10443297769501,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Frankfurt</td>\n",
       "      <td>9.014051</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>POLYGON ((8.47965547981383 50.107440331063444,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Frankfurt</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.1  Unnamed: 0  \\\n",
       "0             0           0   \n",
       "1             1           1   \n",
       "2             2           2   \n",
       "3             3           3   \n",
       "4             4           4   \n",
       "\n",
       "                                            geometry  parking  edges  \\\n",
       "0  POLYGON ((8.4727605 50.099822499999995, 8.4730...        0      0   \n",
       "1  POLYGON ((8.4775730092433 50.10302720327834, 8...        0      0   \n",
       "2  POLYGON ((8.479750879173663 50.09863320231676,...        0      0   \n",
       "3  POLYGON ((8.479688060978736 50.10443297769501,...        0      0   \n",
       "4  POLYGON ((8.47965547981383 50.107440331063444,...        0      0   \n",
       "\n",
       "   EV_stations  parking_space  civic  restaurant  park  ...  cinema  library  \\\n",
       "0            0              0      0           0     0  ...       0        0   \n",
       "1            0              0      0           0     0  ...       0        0   \n",
       "2            0              0      0           0     0  ...       0        0   \n",
       "3            0              0      0           0     0  ...       0        0   \n",
       "4            0              0      0           0     0  ...       0        0   \n",
       "\n",
       "   commercial  retail  townhall  government  residential       city  \\\n",
       "0           0       0         0         0.0            0  Frankfurt   \n",
       "1           0       0         0         0.0            0  Frankfurt   \n",
       "2           0       0         0         0.0            0  Frankfurt   \n",
       "3           0       0         0         0.0            0  Frankfurt   \n",
       "4           0       0         0         0.0            0  Frankfurt   \n",
       "\n",
       "   population  Berlin_data_onlycenter_  \n",
       "0    9.014051                      NaN  \n",
       "1    0.000000                      NaN  \n",
       "2    9.014051                      NaN  \n",
       "3    9.014051                      NaN  \n",
       "4    0.000000                      NaN  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data size: (10824, 22)\n",
      "data size after dropping na: (10129, 22)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geometry</th>\n",
       "      <th>city</th>\n",
       "      <th>EV_stations</th>\n",
       "      <th>parking</th>\n",
       "      <th>edges</th>\n",
       "      <th>parking_space</th>\n",
       "      <th>civic</th>\n",
       "      <th>restaurant</th>\n",
       "      <th>park</th>\n",
       "      <th>school</th>\n",
       "      <th>...</th>\n",
       "      <th>place_of_worship</th>\n",
       "      <th>university</th>\n",
       "      <th>cinema</th>\n",
       "      <th>library</th>\n",
       "      <th>commercial</th>\n",
       "      <th>retail</th>\n",
       "      <th>townhall</th>\n",
       "      <th>government</th>\n",
       "      <th>residential</th>\n",
       "      <th>population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>POLYGON ((8.4727605 50.099822499999995, 8.4730...</td>\n",
       "      <td>Frankfurt</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.014051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>POLYGON ((8.4775730092433 50.10302720327834, 8...</td>\n",
       "      <td>Frankfurt</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>POLYGON ((8.479750879173663 50.09863320231676,...</td>\n",
       "      <td>Frankfurt</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.014051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>POLYGON ((8.479688060978736 50.10443297769501,...</td>\n",
       "      <td>Frankfurt</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.014051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>POLYGON ((8.47965547981383 50.107440331063444,...</td>\n",
       "      <td>Frankfurt</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            geometry       city  EV_stations  \\\n",
       "0  POLYGON ((8.4727605 50.099822499999995, 8.4730...  Frankfurt            0   \n",
       "1  POLYGON ((8.4775730092433 50.10302720327834, 8...  Frankfurt            0   \n",
       "2  POLYGON ((8.479750879173663 50.09863320231676,...  Frankfurt            0   \n",
       "3  POLYGON ((8.479688060978736 50.10443297769501,...  Frankfurt            0   \n",
       "4  POLYGON ((8.47965547981383 50.107440331063444,...  Frankfurt            0   \n",
       "\n",
       "   parking  edges  parking_space  civic  restaurant  park  school  ...  \\\n",
       "0        0      0              0      0           0     0       0  ...   \n",
       "1        0      0              0      0           0     0       0  ...   \n",
       "2        0      0              0      0           0     0       0  ...   \n",
       "3        0      0              0      0           0     0       0  ...   \n",
       "4        0      0              0      0           0     0       0  ...   \n",
       "\n",
       "   place_of_worship  university  cinema  library  commercial  retail  \\\n",
       "0                 0           0       0        0           0       0   \n",
       "1                 0           0       0        0           0       0   \n",
       "2                 0           0       0        0           0       0   \n",
       "3                 0           0       0        0           0       0   \n",
       "4                 0           0       0        0           0       0   \n",
       "\n",
       "   townhall  government  residential  population  \n",
       "0         0         0.0            0    9.014051  \n",
       "1         0         0.0            0    0.000000  \n",
       "2         0         0.0            0    9.014051  \n",
       "3         0         0.0            0    9.014051  \n",
       "4         0         0.0            0    0.000000  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#filtering out columsn to be used for modeling\n",
    "data = data[['geometry','city','EV_stations', 'parking', 'edges',\n",
    "        'parking_space', 'civic', 'restaurant', 'park', 'school',\n",
    "       'node', 'Community_centre', 'place_of_worship', 'university', 'cinema',\n",
    "       'library', 'commercial', 'retail', 'townhall', 'government',\n",
    "       'residential', 'population']]\n",
    "print(\"data size:\" , data.shape)\n",
    "data = data.dropna()\n",
    "print(\"data size after dropping na:\" , data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_splitter(data, train_cities=None, test_cities=None, test_size=0.2, random_state=42):\n",
    "\n",
    "    if train_cities is not None:\n",
    "        train = data[data['city'].isin(train_cities)]\n",
    "        test = data[data['city'].isin(test_cities)]\n",
    "\n",
    "\n",
    "        X_train = train.drop(['city','geometry', 'EV_stations'], axis=1)\n",
    "        y_train = train['EV_stations'].astype(int)\n",
    "        y_train = y_train.apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "        X_test = test.drop(['city','geometry', 'EV_stations'], axis=1)\n",
    "        y_test = test['EV_stations'].astype(int)\n",
    "        y_test = y_test.apply(lambda x: 1 if x > 0 else 0)\n",
    "    else:\n",
    "        X = data.drop(['city','geometry', \"EV_stations\"], axis=1)\n",
    "        y = data['EV_stations']\n",
    "        y = y.apply(lambda x: 1 if x > 0 else 0)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=test_size, random_state=random_state)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = data_splitter(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Test Accuracy:  0.8978282329713722\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.98      0.94      1786\n",
      "           1       0.64      0.31      0.42       240\n",
      "\n",
      "    accuracy                           0.90      2026\n",
      "   macro avg       0.78      0.64      0.68      2026\n",
      "weighted avg       0.88      0.90      0.88      2026\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# logistic regression\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "print(\"Logistic Regression Test Accuracy: \", logreg.score(X_test, y_test))\n",
    "# classification report\n",
    "y_pred = logreg.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "977922344cb64fb3b21e3816854d5654",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred for CategoricalNB: index 7 is out of bounds for axis 1 with size 7\n",
      "Error occurred for ClassifierChain: _BaseChain.__init__() missing 1 required positional argument: 'base_estimator'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/semi_supervised/_label_propagation.py:222: RuntimeWarning: invalid value encountered in divide\n",
      "  probabilities /= normalizer\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/semi_supervised/_label_propagation.py:222: RuntimeWarning: invalid value encountered in divide\n",
      "  probabilities /= normalizer\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred for MultiOutputClassifier: MultiOutputClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for NuSVC: specified nu is infeasible\n",
      "Error occurred for OneVsOneClassifier: OneVsOneClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for OneVsRestClassifier: OneVsRestClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for OutputCodeClassifier: OutputCodeClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for RadiusNeighborsClassifier: No neighbors found for test samples array([   0,    1,    2, ..., 2022, 2023, 2025]), you can try using larger radius, giving a label for outliers, or considering removing them from your dataset.\n",
      "Error occurred for StackingClassifier: StackingClassifier.__init__() missing 1 required positional argument: 'estimators'\n",
      "Error occurred for VotingClassifier: VotingClassifier.__init__() missing 1 required positional argument: 'estimators'\n",
      "                             Model  Accuracy  Precision    Recall  F1-score  \\\n",
      "12  HistGradientBoostingClassifier  0.900296   0.767657  0.705403  0.730580   \n",
      "0               AdaBoostClassifier  0.900296   0.768031  0.703600  0.729434   \n",
      "1                BaggingClassifier  0.901777   0.775313  0.697226  0.727038   \n",
      "11      GradientBoostingClassifier  0.899309   0.766435  0.694023  0.722009   \n",
      "8             ExtraTreesClassifier  0.904738   0.795582  0.680872  0.719110   \n",
      "26          RandomForestClassifier  0.903258   0.787600  0.681836  0.718074   \n",
      "16      LinearDiscriminantAnalysis  0.894373   0.750447  0.680403  0.707106   \n",
      "9                       GaussianNB  0.866239   0.687214  0.707727  0.696568   \n",
      "21                   MultinomialNB  0.872162   0.693752  0.693052  0.693401   \n",
      "20                   MLPClassifier  0.901283   0.793799  0.651862  0.692045   \n",
      "4                     ComplementNB  0.855874   0.674136  0.712668  0.689998   \n",
      "25   QuadraticDiscriminantAnalysis  0.861797   0.677888  0.697994  0.687014   \n",
      "19            LogisticRegressionCV  0.897335   0.772769  0.647819  0.684523   \n",
      "2                      BernoulliNB  0.814413   0.658937  0.777517  0.684522   \n",
      "18              LogisticRegression  0.897828   0.777296  0.644492  0.682073   \n",
      "5           DecisionTreeClassifier  0.859822   0.673098  0.691464  0.681478   \n",
      "22                 NearestCentroid  0.794176   0.654741  0.796697  0.675566   \n",
      "17                       LinearSVC  0.894867   0.762937  0.639205  0.674504   \n",
      "27                 RidgeClassifier  0.897828   0.791270  0.624655  0.663200   \n",
      "7              ExtraTreeClassifier  0.853899   0.657082  0.668267  0.662333   \n",
      "28               RidgeClassifierCV  0.897335   0.789299  0.622571  0.660651   \n",
      "10       GaussianProcessClassifier  0.862290   0.660018  0.640566  0.649223   \n",
      "13            KNeighborsClassifier  0.880059   0.698138  0.616380  0.641237   \n",
      "3           CalibratedClassifierCV  0.896841   0.827685  0.591634  0.624965   \n",
      "24                      Perceptron  0.880059   0.694345  0.594739  0.619051   \n",
      "30                             SVC  0.891905   0.780540  0.583424  0.611760   \n",
      "23     PassiveAggressiveClassifier  0.892892   0.837851  0.564147  0.585107   \n",
      "29                   SGDClassifier  0.888450   0.829615  0.539987  0.545341   \n",
      "14                LabelPropagation  0.848963   0.519835  0.508574  0.503470   \n",
      "15                  LabelSpreading  0.848963   0.519835  0.508574  0.503470   \n",
      "6                  DummyClassifier  0.881540   0.440770  0.500000  0.468520   \n",
      "\n",
      "         AUC  Balanced Accuracy  \n",
      "12  0.705403           0.705403  \n",
      "0   0.703600           0.703600  \n",
      "1   0.697226           0.697226  \n",
      "11  0.694023           0.694023  \n",
      "8   0.680872           0.680872  \n",
      "26  0.681836           0.681836  \n",
      "16  0.680403           0.680403  \n",
      "9   0.707727           0.707727  \n",
      "21  0.693052           0.693052  \n",
      "20  0.651862           0.651862  \n",
      "4   0.712668           0.712668  \n",
      "25  0.697994           0.697994  \n",
      "19  0.647819           0.647819  \n",
      "2   0.777517           0.777517  \n",
      "18  0.644492           0.644492  \n",
      "5   0.691464           0.691464  \n",
      "22  0.796697           0.796697  \n",
      "17  0.639205           0.639205  \n",
      "27  0.624655           0.624655  \n",
      "7   0.668267           0.668267  \n",
      "28  0.622571           0.622571  \n",
      "10  0.640566           0.640566  \n",
      "13  0.616380           0.616380  \n",
      "3   0.591634           0.591634  \n",
      "24  0.594739           0.594739  \n",
      "30  0.583424           0.583424  \n",
      "23  0.564147           0.564147  \n",
      "29  0.539987           0.539987  \n",
      "14  0.508574           0.508574  \n",
      "15  0.508574           0.508574  \n",
      "6   0.500000           0.500000  \n"
     ]
    }
   ],
   "source": [
    "# Get all classification model classes\n",
    "classifiers = all_estimators(type_filter='classifier')\n",
    "\n",
    "# Initialize result table\n",
    "results = []\n",
    "models = {}\n",
    "# Run models and collect results\n",
    "for name, ClassifierClass in tqdm(classifiers):\n",
    "    try:\n",
    "        # Initialize model\n",
    "        model = ClassifierClass()\n",
    "        model.fit(X_train, y_train)\n",
    "        models[name] = model\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred, average='macro')\n",
    "        recall = recall_score(y_test, y_pred, average='macro')\n",
    "        f1 = f1_score(y_test, y_pred, average='macro')\n",
    "        auc = roc_auc_score(y_test, y_pred)\n",
    "        balanced_accuracy = balanced_accuracy_score(y_test, y_pred)\n",
    "        \n",
    "        # Append results\n",
    "        results.append([name, accuracy, precision, recall, f1, auc, balanced_accuracy])\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred for {name}: {str(e)}\")\n",
    "\n",
    "# Create a DataFrame from results\n",
    "results_df = pd.DataFrame(results, columns=[\"Model\", \"Accuracy\", \"Precision\", \"Recall\", \"F1-score\", \"AUC\", \"Balanced Accuracy\"])\n",
    "results_df = results_df.sort_values(by=['F1-score', 'AUC'], ascending=False)\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(X_train, X_test, y_train, y_test):\n",
    "    # Get all classification model classes\n",
    "    classifiers = all_estimators(type_filter='classifier')\n",
    "\n",
    "    # Initialize result table\n",
    "    results = []\n",
    "    models = {}\n",
    "    # Run models and collect results\n",
    "    for name, ClassifierClass in tqdm(classifiers):\n",
    "        try:\n",
    "            # Initialize model\n",
    "            model = ClassifierClass()\n",
    "            model.fit(X_train, y_train)\n",
    "            models[name] = model\n",
    "            y_pred = model.predict(X_test)\n",
    "            \n",
    "            # Calculate metrics\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            precision = precision_score(y_test, y_pred, average='macro')\n",
    "            recall = recall_score(y_test, y_pred, average='macro')\n",
    "            f1 = f1_score(y_test, y_pred, average='macro')\n",
    "            auc = roc_auc_score(y_test, y_pred)\n",
    "            balanced_accuracy = balanced_accuracy_score(y_test, y_pred)\n",
    "            \n",
    "            # Append results\n",
    "            results.append([name, accuracy, precision, recall, f1, auc, balanced_accuracy])\n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred for {name}: {str(e)}\")\n",
    "\n",
    "    # Create a DataFrame from results\n",
    "    results_df = pd.DataFrame(results, columns=[\"Model\", \"Accuracy\", \"Precision\", \"Recall\", \"F1-score\", \"AUC\", \"Balanced Accuracy\"])\n",
    "    results_df = results_df.sort_values(by=['F1-score', 'AUC'], ascending=False)\n",
    "    return results_df, models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbf26bd3ee224982a5f2e0445ea822cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred for CategoricalNB: index 47 is out of bounds for axis 1 with size 33\n",
      "Error occurred for ClassifierChain: _BaseChain.__init__() missing 1 required positional argument: 'base_estimator'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/semi_supervised/_label_propagation.py:222: RuntimeWarning: invalid value encountered in divide\n",
      "  probabilities /= normalizer\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/semi_supervised/_label_propagation.py:222: RuntimeWarning: invalid value encountered in divide\n",
      "  probabilities /= normalizer\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred for MultiOutputClassifier: MultiOutputClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for NuSVC: specified nu is infeasible\n",
      "Error occurred for OneVsOneClassifier: OneVsOneClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for OneVsRestClassifier: OneVsRestClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for OutputCodeClassifier: OutputCodeClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for RadiusNeighborsClassifier: No neighbors found for test samples array([  0,   2,   3,   8,  11,  12,  14,  16,  17,  19,  21,  22,  24,\n",
      "        26,  27,  28,  29,  30,  33,  35,  36,  37,  38,  39,  40,  43,\n",
      "        44,  45,  46,  47,  48,  49,  50,  54,  56,  57,  58,  59,  60,\n",
      "        61,  62,  63,  64,  65,  66,  67,  68,  72,  73,  74,  75,  77,\n",
      "        78,  79,  80,  81,  82,  83,  84,  86,  87,  89,  90,  91,  92,\n",
      "        93,  94,  95,  97,  98,  99, 101, 102, 104, 105, 106, 107, 108,\n",
      "       110, 111, 112, 113, 114, 115, 116, 120, 121, 122, 125, 126, 127,\n",
      "       128, 129, 130, 131, 132, 133, 134, 135, 136, 138, 140, 141, 142,\n",
      "       146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,\n",
      "       159, 160, 161, 162, 163, 166, 167, 168, 169, 170, 171, 172, 173,\n",
      "       174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 186, 187, 188,\n",
      "       189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201,\n",
      "       202, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217,\n",
      "       218, 219, 220, 221, 222, 231, 232, 233, 236, 238, 239, 240, 241,\n",
      "       242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254,\n",
      "       255, 256, 257, 261, 262, 263, 264, 269, 270, 271, 272, 273, 274,\n",
      "       275, 276, 277, 278, 279, 281, 282, 283, 284, 285, 286, 287, 288,\n",
      "       292, 293, 294, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306,\n",
      "       307, 308, 309, 310, 311, 312, 313, 318, 319, 322, 323, 324, 325,\n",
      "       326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 337, 338, 339,\n",
      "       344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356,\n",
      "       357, 360, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374,\n",
      "       375, 379, 380, 381, 382, 383, 384, 385, 386, 391, 392, 393, 394,\n",
      "       395, 398, 400, 405, 406, 407, 408, 409, 410, 411, 412, 413, 415,\n",
      "       416, 417, 418, 419, 420, 421, 422, 423, 426, 427, 428, 429, 430,\n",
      "       431, 432, 434, 435, 436, 437, 438, 439, 440, 445, 446, 447, 448,\n",
      "       455, 456, 457, 466, 467, 468, 475, 476, 484, 486, 487]), you can try using larger radius, giving a label for outliers, or considering removing them from your dataset.\n",
      "Error occurred for StackingClassifier: StackingClassifier.__init__() missing 1 required positional argument: 'estimators'\n",
      "Error occurred for VotingClassifier: VotingClassifier.__init__() missing 1 required positional argument: 'estimators'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:887: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "result_df, models = run_experiment(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.918699</td>\n",
       "      <td>0.682059</td>\n",
       "      <td>0.652829</td>\n",
       "      <td>0.665761</td>\n",
       "      <td>0.652829</td>\n",
       "      <td>0.652829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BernoulliNB</td>\n",
       "      <td>0.847561</td>\n",
       "      <td>0.633567</td>\n",
       "      <td>0.812410</td>\n",
       "      <td>0.665443</td>\n",
       "      <td>0.812410</td>\n",
       "      <td>0.812410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>0.922764</td>\n",
       "      <td>0.694304</td>\n",
       "      <td>0.641826</td>\n",
       "      <td>0.662771</td>\n",
       "      <td>0.641826</td>\n",
       "      <td>0.641826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.914634</td>\n",
       "      <td>0.658303</td>\n",
       "      <td>0.624258</td>\n",
       "      <td>0.638514</td>\n",
       "      <td>0.624258</td>\n",
       "      <td>0.624258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0.894309</td>\n",
       "      <td>0.626664</td>\n",
       "      <td>0.652892</td>\n",
       "      <td>0.637969</td>\n",
       "      <td>0.652892</td>\n",
       "      <td>0.652892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>PassiveAggressiveClassifier</td>\n",
       "      <td>0.920732</td>\n",
       "      <td>0.676886</td>\n",
       "      <td>0.614348</td>\n",
       "      <td>0.636859</td>\n",
       "      <td>0.614348</td>\n",
       "      <td>0.614348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.934959</td>\n",
       "      <td>0.789076</td>\n",
       "      <td>0.595624</td>\n",
       "      <td>0.635116</td>\n",
       "      <td>0.595624</td>\n",
       "      <td>0.595624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ExtraTreeClassifier</td>\n",
       "      <td>0.920732</td>\n",
       "      <td>0.671398</td>\n",
       "      <td>0.601157</td>\n",
       "      <td>0.624464</td>\n",
       "      <td>0.601157</td>\n",
       "      <td>0.601157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ComplementNB</td>\n",
       "      <td>0.880081</td>\n",
       "      <td>0.605113</td>\n",
       "      <td>0.645233</td>\n",
       "      <td>0.620127</td>\n",
       "      <td>0.645233</td>\n",
       "      <td>0.645233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.922764</td>\n",
       "      <td>0.676409</td>\n",
       "      <td>0.589059</td>\n",
       "      <td>0.614229</td>\n",
       "      <td>0.589059</td>\n",
       "      <td>0.589059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>0.936992</td>\n",
       "      <td>0.885802</td>\n",
       "      <td>0.570334</td>\n",
       "      <td>0.605514</td>\n",
       "      <td>0.570334</td>\n",
       "      <td>0.570334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>RidgeClassifier</td>\n",
       "      <td>0.930894</td>\n",
       "      <td>0.746722</td>\n",
       "      <td>0.567052</td>\n",
       "      <td>0.595551</td>\n",
       "      <td>0.567052</td>\n",
       "      <td>0.567052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>RidgeClassifierCV</td>\n",
       "      <td>0.930894</td>\n",
       "      <td>0.746722</td>\n",
       "      <td>0.567052</td>\n",
       "      <td>0.595551</td>\n",
       "      <td>0.567052</td>\n",
       "      <td>0.567052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>0.760163</td>\n",
       "      <td>0.597732</td>\n",
       "      <td>0.804939</td>\n",
       "      <td>0.595338</td>\n",
       "      <td>0.804939</td>\n",
       "      <td>0.804939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>LogisticRegressionCV</td>\n",
       "      <td>0.914634</td>\n",
       "      <td>0.627239</td>\n",
       "      <td>0.571491</td>\n",
       "      <td>0.588530</td>\n",
       "      <td>0.571491</td>\n",
       "      <td>0.571491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>GaussianProcessClassifier</td>\n",
       "      <td>0.908537</td>\n",
       "      <td>0.605513</td>\n",
       "      <td>0.568209</td>\n",
       "      <td>0.580991</td>\n",
       "      <td>0.568209</td>\n",
       "      <td>0.568209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LinearDiscriminantAnalysis</td>\n",
       "      <td>0.908537</td>\n",
       "      <td>0.605513</td>\n",
       "      <td>0.568209</td>\n",
       "      <td>0.580991</td>\n",
       "      <td>0.568209</td>\n",
       "      <td>0.568209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>0.932927</td>\n",
       "      <td>0.801440</td>\n",
       "      <td>0.554955</td>\n",
       "      <td>0.580064</td>\n",
       "      <td>0.554955</td>\n",
       "      <td>0.554955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.918699</td>\n",
       "      <td>0.635220</td>\n",
       "      <td>0.560488</td>\n",
       "      <td>0.578587</td>\n",
       "      <td>0.560488</td>\n",
       "      <td>0.560488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>0.922764</td>\n",
       "      <td>0.649594</td>\n",
       "      <td>0.549484</td>\n",
       "      <td>0.566701</td>\n",
       "      <td>0.549484</td>\n",
       "      <td>0.549484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CalibratedClassifierCV</td>\n",
       "      <td>0.934959</td>\n",
       "      <td>0.967280</td>\n",
       "      <td>0.542857</td>\n",
       "      <td>0.562034</td>\n",
       "      <td>0.542857</td>\n",
       "      <td>0.542857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>0.934959</td>\n",
       "      <td>0.967280</td>\n",
       "      <td>0.542857</td>\n",
       "      <td>0.562034</td>\n",
       "      <td>0.542857</td>\n",
       "      <td>0.542857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>HistGradientBoostingClassifier</td>\n",
       "      <td>0.926829</td>\n",
       "      <td>0.681296</td>\n",
       "      <td>0.538481</td>\n",
       "      <td>0.552320</td>\n",
       "      <td>0.538481</td>\n",
       "      <td>0.538481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>0.920732</td>\n",
       "      <td>0.616805</td>\n",
       "      <td>0.535198</td>\n",
       "      <td>0.545900</td>\n",
       "      <td>0.535198</td>\n",
       "      <td>0.535198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.930894</td>\n",
       "      <td>0.965377</td>\n",
       "      <td>0.514286</td>\n",
       "      <td>0.509845</td>\n",
       "      <td>0.514286</td>\n",
       "      <td>0.514286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DummyClassifier</td>\n",
       "      <td>0.928862</td>\n",
       "      <td>0.464431</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.481560</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.928862</td>\n",
       "      <td>0.464431</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.481560</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.928862</td>\n",
       "      <td>0.464431</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.481560</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LabelPropagation</td>\n",
       "      <td>0.926829</td>\n",
       "      <td>0.464358</td>\n",
       "      <td>0.498906</td>\n",
       "      <td>0.481013</td>\n",
       "      <td>0.498906</td>\n",
       "      <td>0.498906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LabelSpreading</td>\n",
       "      <td>0.926829</td>\n",
       "      <td>0.464358</td>\n",
       "      <td>0.498906</td>\n",
       "      <td>0.481013</td>\n",
       "      <td>0.498906</td>\n",
       "      <td>0.498906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.922764</td>\n",
       "      <td>0.464213</td>\n",
       "      <td>0.496718</td>\n",
       "      <td>0.479915</td>\n",
       "      <td>0.496718</td>\n",
       "      <td>0.496718</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Model  Accuracy  Precision    Recall  F1-score  \\\n",
       "5           DecisionTreeClassifier  0.918699   0.682059  0.652829  0.665761   \n",
       "2                      BernoulliNB  0.847561   0.633567  0.812410  0.665443   \n",
       "1                BaggingClassifier  0.922764   0.694304  0.641826  0.662771   \n",
       "18              LogisticRegression  0.914634   0.658303  0.624258  0.638514   \n",
       "21                   MultinomialNB  0.894309   0.626664  0.652892  0.637969   \n",
       "23     PassiveAggressiveClassifier  0.920732   0.676886  0.614348  0.636859   \n",
       "26          RandomForestClassifier  0.934959   0.789076  0.595624  0.635116   \n",
       "7              ExtraTreeClassifier  0.920732   0.671398  0.601157  0.624464   \n",
       "4                     ComplementNB  0.880081   0.605113  0.645233  0.620127   \n",
       "0               AdaBoostClassifier  0.922764   0.676409  0.589059  0.614229   \n",
       "8             ExtraTreesClassifier  0.936992   0.885802  0.570334  0.605514   \n",
       "27                 RidgeClassifier  0.930894   0.746722  0.567052  0.595551   \n",
       "28               RidgeClassifierCV  0.930894   0.746722  0.567052  0.595551   \n",
       "22                 NearestCentroid  0.760163   0.597732  0.804939  0.595338   \n",
       "19            LogisticRegressionCV  0.914634   0.627239  0.571491  0.588530   \n",
       "10       GaussianProcessClassifier  0.908537   0.605513  0.568209  0.580991   \n",
       "16      LinearDiscriminantAnalysis  0.908537   0.605513  0.568209  0.580991   \n",
       "24                      Perceptron  0.932927   0.801440  0.554955  0.580064   \n",
       "11      GradientBoostingClassifier  0.918699   0.635220  0.560488  0.578587   \n",
       "25   QuadraticDiscriminantAnalysis  0.922764   0.649594  0.549484  0.566701   \n",
       "3           CalibratedClassifierCV  0.934959   0.967280  0.542857  0.562034   \n",
       "29                   SGDClassifier  0.934959   0.967280  0.542857  0.562034   \n",
       "12  HistGradientBoostingClassifier  0.926829   0.681296  0.538481  0.552320   \n",
       "17                       LinearSVC  0.920732   0.616805  0.535198  0.545900   \n",
       "13            KNeighborsClassifier  0.930894   0.965377  0.514286  0.509845   \n",
       "6                  DummyClassifier  0.928862   0.464431  0.500000  0.481560   \n",
       "9                       GaussianNB  0.928862   0.464431  0.500000  0.481560   \n",
       "30                             SVC  0.928862   0.464431  0.500000  0.481560   \n",
       "14                LabelPropagation  0.926829   0.464358  0.498906  0.481013   \n",
       "15                  LabelSpreading  0.926829   0.464358  0.498906  0.481013   \n",
       "20                   MLPClassifier  0.922764   0.464213  0.496718  0.479915   \n",
       "\n",
       "         AUC  Balanced Accuracy  \n",
       "5   0.652829           0.652829  \n",
       "2   0.812410           0.812410  \n",
       "1   0.641826           0.641826  \n",
       "18  0.624258           0.624258  \n",
       "21  0.652892           0.652892  \n",
       "23  0.614348           0.614348  \n",
       "26  0.595624           0.595624  \n",
       "7   0.601157           0.601157  \n",
       "4   0.645233           0.645233  \n",
       "0   0.589059           0.589059  \n",
       "8   0.570334           0.570334  \n",
       "27  0.567052           0.567052  \n",
       "28  0.567052           0.567052  \n",
       "22  0.804939           0.804939  \n",
       "19  0.571491           0.571491  \n",
       "10  0.568209           0.568209  \n",
       "16  0.568209           0.568209  \n",
       "24  0.554955           0.554955  \n",
       "11  0.560488           0.560488  \n",
       "25  0.549484           0.549484  \n",
       "3   0.542857           0.542857  \n",
       "29  0.542857           0.542857  \n",
       "12  0.538481           0.538481  \n",
       "17  0.535198           0.535198  \n",
       "13  0.514286           0.514286  \n",
       "6   0.500000           0.500000  \n",
       "9   0.500000           0.500000  \n",
       "30  0.500000           0.500000  \n",
       "14  0.498906           0.498906  \n",
       "15  0.498906           0.498906  \n",
       "20  0.496718           0.496718  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv(\"/home/bahramkhanbaloch/media3/MS/Semester1/DS/results/all_cities_random_shuffle.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d30a22cfa1b7409f94d93533ee7e075d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08a7c626c2c1430893e6104aadff06d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred for CategoricalNB: index 51 is out of bounds for axis 1 with size 51\n",
      "Error occurred for ClassifierChain: _BaseChain.__init__() missing 1 required positional argument: 'base_estimator'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/semi_supervised/_label_propagation.py:222: RuntimeWarning: invalid value encountered in divide\n",
      "  probabilities /= normalizer\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/semi_supervised/_label_propagation.py:222: RuntimeWarning: invalid value encountered in divide\n",
      "  probabilities /= normalizer\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred for MultiOutputClassifier: MultiOutputClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for NuSVC: specified nu is infeasible\n",
      "Error occurred for OneVsOneClassifier: OneVsOneClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for OneVsRestClassifier: OneVsRestClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for OutputCodeClassifier: OutputCodeClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for RadiusNeighborsClassifier: No neighbors found for test samples array([   2,    9,   17, ..., 3877, 3878, 3879]), you can try using larger radius, giving a label for outliers, or considering removing them from your dataset.\n",
      "Error occurred for StackingClassifier: StackingClassifier.__init__() missing 1 required positional argument: 'estimators'\n",
      "Error occurred for VotingClassifier: VotingClassifier.__init__() missing 1 required positional argument: 'estimators'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c92f17cba5294876aa74346cd90bd177",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred for CategoricalNB: index 53 is out of bounds for axis 1 with size 48\n",
      "Error occurred for ClassifierChain: _BaseChain.__init__() missing 1 required positional argument: 'base_estimator'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/semi_supervised/_label_propagation.py:222: RuntimeWarning: invalid value encountered in divide\n",
      "  probabilities /= normalizer\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/semi_supervised/_label_propagation.py:222: RuntimeWarning: invalid value encountered in divide\n",
      "  probabilities /= normalizer\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred for MultiOutputClassifier: MultiOutputClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for NuSVC: specified nu is infeasible\n",
      "Error occurred for OneVsOneClassifier: OneVsOneClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for OneVsRestClassifier: OneVsRestClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for OutputCodeClassifier: OutputCodeClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for RadiusNeighborsClassifier: No neighbors found for test samples array([  15,   17,   22, ..., 1409, 1410, 1420]), you can try using larger radius, giving a label for outliers, or considering removing them from your dataset.\n",
      "Error occurred for StackingClassifier: StackingClassifier.__init__() missing 1 required positional argument: 'estimators'\n",
      "Error occurred for VotingClassifier: VotingClassifier.__init__() missing 1 required positional argument: 'estimators'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31475c86e0a84b208ee72addc7ee479d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred for CategoricalNB: index 13 is out of bounds for axis 1 with size 10\n",
      "Error occurred for ClassifierChain: _BaseChain.__init__() missing 1 required positional argument: 'base_estimator'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/semi_supervised/_label_propagation.py:222: RuntimeWarning: invalid value encountered in divide\n",
      "  probabilities /= normalizer\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/semi_supervised/_label_propagation.py:222: RuntimeWarning: invalid value encountered in divide\n",
      "  probabilities /= normalizer\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred for MultiOutputClassifier: MultiOutputClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for NuSVC: specified nu is infeasible\n",
      "Error occurred for OneVsOneClassifier: OneVsOneClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for OneVsRestClassifier: OneVsRestClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for OutputCodeClassifier: OutputCodeClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for RadiusNeighborsClassifier: No neighbors found for test samples array([ 11,  20,  21,  23,  27,  30,  31,  32,  39,  40,  41,  42,  43,\n",
      "        44,  45,  46,  49,  50,  51,  52,  54,  55,  56,  57,  58,  59,\n",
      "        64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  77,\n",
      "        79,  80,  81,  82,  84,  85,  86,  95,  98,  99, 100, 101, 102,\n",
      "       103, 104, 106, 107, 108, 109, 110, 111, 112, 119, 122, 123, 124,\n",
      "       125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137,\n",
      "       138, 139, 144, 147, 150, 151, 152, 153, 154, 155, 156, 157, 158,\n",
      "       159, 162, 163, 164, 165, 166, 167, 171, 172, 173, 174, 175, 176,\n",
      "       177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 189, 190, 191,\n",
      "       192, 193, 198, 199, 200, 201, 202, 203, 206, 207, 208, 209, 210,\n",
      "       211, 212, 213, 216, 219, 220, 225, 226, 227, 228, 230, 232, 233,\n",
      "       234, 235, 236, 237, 238, 239, 240, 246, 248, 250, 251, 252, 253,\n",
      "       256, 257, 258, 259, 260, 261, 263, 264, 265, 266, 267, 268, 269,\n",
      "       270, 271, 272, 274, 275, 277, 278, 280, 281, 282, 285, 286, 287,\n",
      "       288, 289, 290, 292, 293, 294, 295, 296, 297, 298, 299, 301, 302,\n",
      "       303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315,\n",
      "       316, 317, 318, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329,\n",
      "       330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342,\n",
      "       343, 344, 346, 347, 348, 349, 350, 351, 352, 354, 355, 356, 357,\n",
      "       358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370,\n",
      "       371, 372, 373, 374, 375, 376, 377, 378, 379, 381, 382, 383, 384,\n",
      "       385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397,\n",
      "       398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410,\n",
      "       411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423,\n",
      "       424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436,\n",
      "       437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 450,\n",
      "       451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463,\n",
      "       464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 477, 484,\n",
      "       485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497,\n",
      "       498, 499, 500, 501, 502, 503, 505, 506, 507, 509, 511, 512, 521,\n",
      "       522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534,\n",
      "       535, 536, 537, 538, 540, 541, 542, 547, 548, 549, 553, 557, 558,\n",
      "       559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571,\n",
      "       572, 573, 574, 577, 578, 579, 581, 582, 583, 585, 586, 589, 590,\n",
      "       594, 595, 596, 597, 599, 600, 601, 602, 603, 604, 605, 606, 607,\n",
      "       608, 609, 610, 611, 612, 613, 616, 617, 619, 620, 621, 622, 623,\n",
      "       624, 625, 626, 627, 628, 632, 633, 634, 635, 636, 637, 638, 639,\n",
      "       640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 652, 654,\n",
      "       655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667,\n",
      "       669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681,\n",
      "       682, 683, 684, 685, 686, 687, 688, 689, 691, 692, 693, 694, 695,\n",
      "       696, 697, 699, 701, 703, 704, 705, 706, 707, 708, 709, 710, 711,\n",
      "       712, 713, 714, 715, 716, 717, 718, 719, 720, 722, 723, 724, 725,\n",
      "       727, 728, 729, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743,\n",
      "       744, 745, 746, 747, 748, 749, 750, 751, 752, 754, 755, 757, 758,\n",
      "       759, 760, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772,\n",
      "       773, 774, 775, 776, 777, 778, 779, 780, 782, 783, 784, 785, 786,\n",
      "       794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806,\n",
      "       808, 809, 810, 812, 813, 814, 815, 816, 823, 824, 825, 826, 827,\n",
      "       828, 829, 830, 831, 832, 836, 837, 838, 839, 840, 841, 842, 843,\n",
      "       844, 845, 846, 847, 848, 850, 851, 853, 854, 855, 856, 857, 858,\n",
      "       859, 861, 863, 864, 865, 866, 867, 868, 869, 873, 874, 875, 876,\n",
      "       878, 880, 887, 901, 902, 903, 904, 905, 906, 907, 910, 911, 912,\n",
      "       913, 914, 929, 930, 933, 934, 938, 939, 941, 956]), you can try using larger radius, giving a label for outliers, or considering removing them from your dataset.\n",
      "Error occurred for StackingClassifier: StackingClassifier.__init__() missing 1 required positional argument: 'estimators'\n",
      "Error occurred for VotingClassifier: VotingClassifier.__init__() missing 1 required positional argument: 'estimators'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "030ce01784024886a760291e74713e12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred for CategoricalNB: index 12 is out of bounds for axis 1 with size 11\n",
      "Error occurred for ClassifierChain: _BaseChain.__init__() missing 1 required positional argument: 'base_estimator'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/semi_supervised/_label_propagation.py:222: RuntimeWarning: invalid value encountered in divide\n",
      "  probabilities /= normalizer\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/semi_supervised/_label_propagation.py:222: RuntimeWarning: invalid value encountered in divide\n",
      "  probabilities /= normalizer\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred for MultiOutputClassifier: MultiOutputClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for NuSVC: specified nu is infeasible\n",
      "Error occurred for OneVsOneClassifier: OneVsOneClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for OneVsRestClassifier: OneVsRestClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for OutputCodeClassifier: OutputCodeClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for RadiusNeighborsClassifier: No neighbors found for test samples array([   6,   12,   13,   19,   20,   21,   27,   28,   29,   30,   31,\n",
      "         32,   33,   41,   43,   44,   45,   46,   55,   56,   57,   58,\n",
      "         59,   60,   61,   66,   67,   68,   69,   70,   71,   79,   80,\n",
      "         81,   82,   83,   84,   86,   88,   89,   90,   91,   92,   93,\n",
      "         94,   95,   96,   97,  101,  102,  103,  104,  105,  106,  107,\n",
      "        108,  109,  110,  115,  116,  117,  118,  120,  121,  122,  123,\n",
      "        129,  130,  136,  138,  139,  141,  142,  153,  154,  159,  160,\n",
      "        162,  163,  164,  165,  166,  167,  168,  171,  178,  179,  186,\n",
      "        187,  188,  189,  192,  193,  194,  195,  196,  197,  204,  205,\n",
      "        206,  210,  213,  215,  216,  219,  220,  221,  222,  223,  224,\n",
      "        225,  226,  227,  232,  238,  239,  243,  244,  245,  249,  250,\n",
      "        251,  253,  254,  260,  261,  265,  266,  267,  270,  273,  274,\n",
      "        275,  276,  279,  280,  281,  282,  283,  284,  285,  286,  291,\n",
      "        292,  296,  303,  305,  306,  307,  308,  309,  310,  311,  312,\n",
      "        313,  314,  315,  316,  317,  318,  319,  320,  324,  325,  326,\n",
      "        336,  337,  338,  339,  340,  341,  342,  343,  344,  345,  346,\n",
      "        347,  348,  349,  351,  352,  357,  364,  365,  366,  367,  368,\n",
      "        369,  370,  371,  372,  373,  374,  375,  376,  377,  378,  379,\n",
      "        380,  381,  382,  383,  384,  385,  386,  394,  396,  397,  398,\n",
      "        399,  400,  401,  402,  403,  404,  405,  406,  407,  408,  409,\n",
      "        410,  411,  412,  413,  414,  415,  416,  417,  418,  419,  420,\n",
      "        425,  426,  428,  429,  430,  431,  432,  433,  434,  435,  436,\n",
      "        438,  439,  440,  441,  442,  443,  444,  445,  446,  447,  448,\n",
      "        449,  450,  451,  452,  453,  455,  459,  462,  463,  464,  465,\n",
      "        466,  467,  468,  469,  470,  471,  472,  473,  474,  475,  476,\n",
      "        477,  478,  479,  480,  481,  482,  483,  484,  485,  486,  487,\n",
      "        488,  489,  490,  494,  496,  497,  498,  499,  500,  502,  503,\n",
      "        504,  505,  506,  507,  508,  509,  510,  511,  512,  513,  514,\n",
      "        515,  516,  517,  518,  519,  520,  521,  522,  523,  524,  525,\n",
      "        527,  530,  531,  532,  533,  535,  538,  539,  540,  541,  542,\n",
      "        543,  544,  545,  546,  547,  548,  549,  550,  551,  552,  553,\n",
      "        554,  555,  556,  557,  558,  559,  560,  561,  562,  566,  567,\n",
      "        568,  569,  570,  571,  573,  574,  575,  576,  577,  578,  579,\n",
      "        580,  581,  582,  583,  584,  585,  586,  587,  588,  589,  590,\n",
      "        591,  592,  593,  594,  596,  602,  603,  604,  605,  606,  607,\n",
      "        608,  610,  611,  612,  613,  614,  615,  616,  617,  618,  619,\n",
      "        620,  621,  622,  623,  624,  625,  626,  627,  628,  629,  631,\n",
      "        638,  639,  640,  642,  643,  644,  647,  648,  649,  650,  651,\n",
      "        652,  653,  654,  655,  656,  657,  658,  659,  660,  661,  662,\n",
      "        663,  664,  665,  666,  667,  670,  672,  676,  677,  683,  684,\n",
      "        685,  686,  687,  688,  689,  690,  691,  692,  693,  694,  695,\n",
      "        696,  697,  698,  699,  700,  701,  702,  703,  704,  706,  709,\n",
      "        718,  722,  723,  724,  725,  726,  727,  728,  729,  730,  731,\n",
      "        732,  733,  734,  735,  736,  737,  738,  739,  740,  741,  744,\n",
      "        746,  747,  755,  756,  758,  759,  760,  761,  762,  763,  764,\n",
      "        765,  766,  767,  768,  769,  770,  771,  772,  773,  774,  775,\n",
      "        776,  777,  778,  784,  787,  788,  791,  792,  793,  794,  795,\n",
      "        798,  799,  800,  801,  802,  803,  804,  805,  806,  807,  808,\n",
      "        809,  810,  811,  812,  813,  814,  815,  824,  825,  826,  836,\n",
      "        837,  838,  866,  867,  868,  869,  870,  871,  872,  873,  874,\n",
      "        875,  876,  877,  878,  879,  880,  881,  894,  895,  896,  897,\n",
      "        898,  899,  900,  901,  902,  903,  904,  905,  906,  907,  909,\n",
      "        912,  917,  918,  919,  922,  923,  924,  925,  926,  927,  928,\n",
      "        929,  930,  931,  932,  933,  934,  937,  939,  941,  943,  944,\n",
      "        945,  946,  948,  949,  950,  951,  952,  953,  955,  956,  957,\n",
      "        966,  967,  968,  969,  970,  971,  972,  973,  974,  975,  976,\n",
      "        978,  979,  980,  981,  982,  983,  984,  985,  986,  987,  988,\n",
      "        992,  993,  994,  995,  996,  997,  998,  999, 1000, 1001, 1006,\n",
      "       1007, 1008, 1009, 1010, 1012, 1013, 1014, 1015, 1016, 1023, 1024,\n",
      "       1025, 1026, 1027, 1028, 1029, 1030, 1031, 1032, 1033, 1040, 1045,\n",
      "       1046, 1047, 1048, 1049, 1050, 1051, 1058, 1063, 1068, 1072, 1084,\n",
      "       1091, 1092, 1093, 1094, 1100, 1105, 1121, 1129, 1130, 1137, 1143,\n",
      "       1145]), you can try using larger radius, giving a label for outliers, or considering removing them from your dataset.\n",
      "Error occurred for StackingClassifier: StackingClassifier.__init__() missing 1 required positional argument: 'estimators'\n",
      "Error occurred for VotingClassifier: VotingClassifier.__init__() missing 1 required positional argument: 'estimators'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fc46bee2e1040c887bd0439a1a1f83a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b25c68000bcf4b258b3d1a9148f922c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred for AdaBoostClassifier: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by AdaBoostClassifier.\n",
      "Error occurred for BaggingClassifier: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by BaggingClassifier.\n",
      "Error occurred for BernoulliNB: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by BernoulliNB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/numpy/lib/function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis, **keepdims_kw)\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/numpy/core/_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/numpy/lib/function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis, **keepdims_kw)\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/numpy/core/_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/numpy/lib/function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis, **keepdims_kw)\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/numpy/core/_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/numpy/lib/function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis, **keepdims_kw)\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/numpy/core/_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred for CalibratedClassifierCV: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by LinearSVC.\n",
      "Error occurred for CategoricalNB: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by CategoricalNB.\n",
      "Error occurred for ClassifierChain: _BaseChain.__init__() missing 1 required positional argument: 'base_estimator'\n",
      "Error occurred for ComplementNB: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by ComplementNB.\n",
      "Error occurred for DecisionTreeClassifier: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by DecisionTreeClassifier.\n",
      "Error occurred for DummyClassifier: Found array with 0 sample(s) (shape=(0,)) while a minimum of 1 is required.\n",
      "Error occurred for ExtraTreeClassifier: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by ExtraTreeClassifier.\n",
      "Error occurred for ExtraTreesClassifier: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by ExtraTreesClassifier.\n",
      "Error occurred for GaussianNB: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by GaussianNB.\n",
      "Error occurred for GaussianProcessClassifier: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by GaussianProcessClassifier.\n",
      "Error occurred for GradientBoostingClassifier: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by GradientBoostingClassifier.\n",
      "Error occurred for HistGradientBoostingClassifier: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by HistGradientBoostingClassifier.\n",
      "Error occurred for KNeighborsClassifier: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by KNeighborsClassifier.\n",
      "Error occurred for LabelPropagation: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by LabelPropagation.\n",
      "Error occurred for LabelSpreading: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by LabelSpreading.\n",
      "Error occurred for LinearDiscriminantAnalysis: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by LinearDiscriminantAnalysis.\n",
      "Error occurred for LinearSVC: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by LinearSVC.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred for LogisticRegression: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by LogisticRegression.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred for LogisticRegressionCV: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by LogisticRegressionCV.\n",
      "Error occurred for MLPClassifier: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by MLPClassifier.\n",
      "Error occurred for MultiOutputClassifier: MultiOutputClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for MultinomialNB: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by MultinomialNB.\n",
      "Error occurred for NearestCentroid: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by NearestCentroid.\n",
      "Error occurred for NuSVC: specified nu is infeasible\n",
      "Error occurred for OneVsOneClassifier: OneVsOneClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for OneVsRestClassifier: OneVsRestClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for OutputCodeClassifier: OutputCodeClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for PassiveAggressiveClassifier: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by PassiveAggressiveClassifier.\n",
      "Error occurred for Perceptron: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by Perceptron.\n",
      "Error occurred for QuadraticDiscriminantAnalysis: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by QuadraticDiscriminantAnalysis.\n",
      "Error occurred for RadiusNeighborsClassifier: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by RadiusNeighborsClassifier.\n",
      "Error occurred for RandomForestClassifier: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by RandomForestClassifier.\n",
      "Error occurred for RidgeClassifier: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by RidgeClassifier.\n",
      "Error occurred for RidgeClassifierCV: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by RidgeClassifierCV.\n",
      "Error occurred for SGDClassifier: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by SGDClassifier.\n",
      "Error occurred for SVC: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by SVC.\n",
      "Error occurred for StackingClassifier: StackingClassifier.__init__() missing 1 required positional argument: 'estimators'\n",
      "Error occurred for VotingClassifier: VotingClassifier.__init__() missing 1 required positional argument: 'estimators'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6eb4569a91ae4d588c9f53a46a8252b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred for CategoricalNB: index 87 is out of bounds for axis 1 with size 46\n",
      "Error occurred for ClassifierChain: _BaseChain.__init__() missing 1 required positional argument: 'base_estimator'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/semi_supervised/_label_propagation.py:222: RuntimeWarning: invalid value encountered in divide\n",
      "  probabilities /= normalizer\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/semi_supervised/_label_propagation.py:222: RuntimeWarning: invalid value encountered in divide\n",
      "  probabilities /= normalizer\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:887: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred for MultiOutputClassifier: MultiOutputClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for NuSVC: specified nu is infeasible\n",
      "Error occurred for OneVsOneClassifier: OneVsOneClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for OneVsRestClassifier: OneVsRestClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for OutputCodeClassifier: OutputCodeClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for RadiusNeighborsClassifier: No neighbors found for test samples array([  7,  11,  15,  21,  25,  27,  28,  29,  39,  40,  41,  42,  43,\n",
      "        47,  51,  52,  53,  54,  55,  58,  59,  63,  64,  65,  66,  70,\n",
      "        71,  72,  73,  74,  75,  76,  82,  83,  84,  85,  86,  87,  88,\n",
      "        90,  91,  92,  93,  94,  95,  96,  97,  98,  99, 102, 103, 104,\n",
      "       105, 106, 107, 108, 109, 110, 112, 115, 116, 120, 121, 122, 123,\n",
      "       124, 125, 126, 127, 128, 129, 130, 131, 133, 135, 137, 138, 139,\n",
      "       140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 153,\n",
      "       154, 155, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171,\n",
      "       172, 182, 183, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "       196, 197, 208, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "       220, 221, 230, 231, 236, 237, 238, 239, 240, 241, 242, 243, 244,\n",
      "       245, 246, 247, 248, 262, 263, 264, 265, 266, 267, 268, 269, 270,\n",
      "       271, 272, 273, 275, 279, 284, 285, 288, 290, 291, 292, 293, 294,\n",
      "       295, 296, 297, 298, 299, 300, 301, 302, 303, 319, 320, 324, 325,\n",
      "       326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338,\n",
      "       339, 340, 341, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,\n",
      "       364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 386,\n",
      "       387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 399, 408,\n",
      "       409, 410, 411, 413, 414, 415, 416, 417, 418, 419, 426, 427, 428,\n",
      "       429, 432, 434, 435, 436, 437, 443, 444, 445, 446, 450, 453, 456,\n",
      "       470, 471, 472, 473, 474, 477, 478, 479, 480, 481, 483, 484, 486,\n",
      "       487, 488, 497, 498, 499, 500, 501, 502, 503, 504, 505, 507, 510,\n",
      "       511, 512, 513, 514, 515, 516, 517, 518, 524, 525, 526, 527, 528,\n",
      "       529, 538, 539, 540, 554, 563, 564, 569, 570, 578, 581, 582]), you can try using larger radius, giving a label for outliers, or considering removing them from your dataset.\n",
      "Error occurred for StackingClassifier: StackingClassifier.__init__() missing 1 required positional argument: 'estimators'\n",
      "Error occurred for VotingClassifier: VotingClassifier.__init__() missing 1 required positional argument: 'estimators'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e259d8affbc14a86933d3b6ad8dfe4e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred for AdaBoostClassifier: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by AdaBoostClassifier.\n",
      "Error occurred for BaggingClassifier: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by BaggingClassifier.\n",
      "Error occurred for BernoulliNB: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by BernoulliNB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/numpy/lib/function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis, **keepdims_kw)\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/numpy/core/_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/numpy/lib/function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis, **keepdims_kw)\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/numpy/core/_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/numpy/lib/function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis, **keepdims_kw)\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/numpy/core/_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/numpy/lib/function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis, **keepdims_kw)\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/numpy/core/_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred for CalibratedClassifierCV: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by LinearSVC.\n",
      "Error occurred for CategoricalNB: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by CategoricalNB.\n",
      "Error occurred for ClassifierChain: _BaseChain.__init__() missing 1 required positional argument: 'base_estimator'\n",
      "Error occurred for ComplementNB: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by ComplementNB.\n",
      "Error occurred for DecisionTreeClassifier: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by DecisionTreeClassifier.\n",
      "Error occurred for DummyClassifier: Found array with 0 sample(s) (shape=(0,)) while a minimum of 1 is required.\n",
      "Error occurred for ExtraTreeClassifier: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by ExtraTreeClassifier.\n",
      "Error occurred for ExtraTreesClassifier: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by ExtraTreesClassifier.\n",
      "Error occurred for GaussianNB: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by GaussianNB.\n",
      "Error occurred for GaussianProcessClassifier: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by GaussianProcessClassifier.\n",
      "Error occurred for GradientBoostingClassifier: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by GradientBoostingClassifier.\n",
      "Error occurred for HistGradientBoostingClassifier: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by HistGradientBoostingClassifier.\n",
      "Error occurred for KNeighborsClassifier: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by KNeighborsClassifier.\n",
      "Error occurred for LabelPropagation: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by LabelPropagation.\n",
      "Error occurred for LabelSpreading: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by LabelSpreading.\n",
      "Error occurred for LinearDiscriminantAnalysis: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by LinearDiscriminantAnalysis.\n",
      "Error occurred for LinearSVC: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by LinearSVC.\n",
      "Error occurred for LogisticRegression: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by LogisticRegression.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred for LogisticRegressionCV: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by LogisticRegressionCV.\n",
      "Error occurred for MLPClassifier: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by MLPClassifier.\n",
      "Error occurred for MultiOutputClassifier: MultiOutputClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for MultinomialNB: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by MultinomialNB.\n",
      "Error occurred for NearestCentroid: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by NearestCentroid.\n",
      "Error occurred for NuSVC: specified nu is infeasible\n",
      "Error occurred for OneVsOneClassifier: OneVsOneClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for OneVsRestClassifier: OneVsRestClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for OutputCodeClassifier: OutputCodeClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for PassiveAggressiveClassifier: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by PassiveAggressiveClassifier.\n",
      "Error occurred for Perceptron: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by Perceptron.\n",
      "Error occurred for QuadraticDiscriminantAnalysis: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by QuadraticDiscriminantAnalysis.\n",
      "Error occurred for RadiusNeighborsClassifier: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by RadiusNeighborsClassifier.\n",
      "Error occurred for RandomForestClassifier: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by RandomForestClassifier.\n",
      "Error occurred for RidgeClassifier: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by RidgeClassifier.\n",
      "Error occurred for RidgeClassifierCV: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by RidgeClassifierCV.\n",
      "Error occurred for SGDClassifier: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by SGDClassifier.\n",
      "Error occurred for SVC: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by SVC.\n",
      "Error occurred for StackingClassifier: StackingClassifier.__init__() missing 1 required positional argument: 'estimators'\n",
      "Error occurred for VotingClassifier: VotingClassifier.__init__() missing 1 required positional argument: 'estimators'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfd1531cae544ac7847a04ad5bc101ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred for CategoricalNB: index 47 is out of bounds for axis 1 with size 33\n",
      "Error occurred for ClassifierChain: _BaseChain.__init__() missing 1 required positional argument: 'base_estimator'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/semi_supervised/_label_propagation.py:222: RuntimeWarning: invalid value encountered in divide\n",
      "  probabilities /= normalizer\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/semi_supervised/_label_propagation.py:222: RuntimeWarning: invalid value encountered in divide\n",
      "  probabilities /= normalizer\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:887: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred for MultiOutputClassifier: MultiOutputClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for NuSVC: specified nu is infeasible\n",
      "Error occurred for OneVsOneClassifier: OneVsOneClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for OneVsRestClassifier: OneVsRestClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for OutputCodeClassifier: OutputCodeClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for RadiusNeighborsClassifier: No neighbors found for test samples array([  0,   2,   3,   8,  11,  12,  14,  16,  17,  19,  21,  22,  24,\n",
      "        26,  27,  28,  29,  30,  33,  35,  36,  37,  38,  39,  40,  43,\n",
      "        44,  45,  46,  47,  48,  49,  50,  54,  56,  57,  58,  59,  60,\n",
      "        61,  62,  63,  64,  65,  66,  67,  68,  72,  73,  74,  75,  77,\n",
      "        78,  79,  80,  81,  82,  83,  84,  86,  87,  89,  90,  91,  92,\n",
      "        93,  94,  95,  97,  98,  99, 101, 102, 104, 105, 106, 107, 108,\n",
      "       110, 111, 112, 113, 114, 115, 116, 120, 121, 122, 125, 126, 127,\n",
      "       128, 129, 130, 131, 132, 133, 134, 135, 136, 138, 140, 141, 142,\n",
      "       146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,\n",
      "       159, 160, 161, 162, 163, 166, 167, 168, 169, 170, 171, 172, 173,\n",
      "       174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 186, 187, 188,\n",
      "       189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201,\n",
      "       202, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217,\n",
      "       218, 219, 220, 221, 222, 231, 232, 233, 236, 238, 239, 240, 241,\n",
      "       242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254,\n",
      "       255, 256, 257, 261, 262, 263, 264, 269, 270, 271, 272, 273, 274,\n",
      "       275, 276, 277, 278, 279, 281, 282, 283, 284, 285, 286, 287, 288,\n",
      "       292, 293, 294, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306,\n",
      "       307, 308, 309, 310, 311, 312, 313, 318, 319, 322, 323, 324, 325,\n",
      "       326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 337, 338, 339,\n",
      "       344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356,\n",
      "       357, 360, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374,\n",
      "       375, 379, 380, 381, 382, 383, 384, 385, 386, 391, 392, 393, 394,\n",
      "       395, 398, 400, 405, 406, 407, 408, 409, 410, 411, 412, 413, 415,\n",
      "       416, 417, 418, 419, 420, 421, 422, 423, 426, 427, 428, 429, 430,\n",
      "       431, 432, 434, 435, 436, 437, 438, 439, 440, 445, 446, 447, 448,\n",
      "       455, 456, 457, 466, 467, 468, 475, 476, 484, 486, 487]), you can try using larger radius, giving a label for outliers, or considering removing them from your dataset.\n",
      "Error occurred for StackingClassifier: StackingClassifier.__init__() missing 1 required positional argument: 'estimators'\n",
      "Error occurred for VotingClassifier: VotingClassifier.__init__() missing 1 required positional argument: 'estimators'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Berlin, Munich, Stuttgart, Frankfurt: Big CITY EXP-1\n",
    "Kalsruhe, trier, saarbrucken, mainz: EXP-2\n",
    "\"\"\"\n",
    "\n",
    "# EXP-1\n",
    "big_cities = ['Berlin', 'Munich', 'Stuttgart', 'Frankfurt']\n",
    "small_cities = ['Karlsruhe', 'Trier', 'SaarbrÃ¼cken', 'Mainz']\n",
    "\n",
    "\n",
    "# make a table in the end to summarise the results of all experiments\n",
    "\n",
    "# big cities splited in trian and test where only one big city is test and all possible combinations for this\n",
    "for city in tqdm(big_cities):\n",
    "    test_cities = [city]\n",
    "    train_cities = [x for x in big_cities if x != city]\n",
    "    X_train, X_test, y_train, y_test = data_splitter(data, train_cities=train_cities, test_cities=test_cities)\n",
    "    results_df, models = run_experiment(X_train, X_test, y_train, y_test)\n",
    "    results_df.to_csv(f\"/home/bahramkhanbaloch/media3/MS/Semester1/DS/results/big_cities_test_city_{city}_.csv\", index=False)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "# small cities splited in trian and test where only one small city is test and all possible combinations for this\n",
    "for city in tqdm(small_cities):\n",
    "    test_cities = [city]\n",
    "    train_cities = [x for x in small_cities if x != city]\n",
    "    X_train, X_test, y_train, y_test = data_splitter(data, train_cities=train_cities, test_cities=test_cities)\n",
    "    results_df, models = run_experiment(X_train, X_test, y_train, y_test)\n",
    "    results_df.to_csv(f\"/home/bahramkhanbaloch/media3/MS/Semester1/DS/results/small_cities_test_city_{city}_.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.918699</td>\n",
       "      <td>0.682059</td>\n",
       "      <td>0.652829</td>\n",
       "      <td>0.665761</td>\n",
       "      <td>0.652829</td>\n",
       "      <td>0.652829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BernoulliNB</td>\n",
       "      <td>0.847561</td>\n",
       "      <td>0.633567</td>\n",
       "      <td>0.812410</td>\n",
       "      <td>0.665443</td>\n",
       "      <td>0.812410</td>\n",
       "      <td>0.812410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>0.922764</td>\n",
       "      <td>0.694304</td>\n",
       "      <td>0.641826</td>\n",
       "      <td>0.662771</td>\n",
       "      <td>0.641826</td>\n",
       "      <td>0.641826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.914634</td>\n",
       "      <td>0.658303</td>\n",
       "      <td>0.624258</td>\n",
       "      <td>0.638514</td>\n",
       "      <td>0.624258</td>\n",
       "      <td>0.624258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0.894309</td>\n",
       "      <td>0.626664</td>\n",
       "      <td>0.652892</td>\n",
       "      <td>0.637969</td>\n",
       "      <td>0.652892</td>\n",
       "      <td>0.652892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>PassiveAggressiveClassifier</td>\n",
       "      <td>0.920732</td>\n",
       "      <td>0.676886</td>\n",
       "      <td>0.614348</td>\n",
       "      <td>0.636859</td>\n",
       "      <td>0.614348</td>\n",
       "      <td>0.614348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.934959</td>\n",
       "      <td>0.789076</td>\n",
       "      <td>0.595624</td>\n",
       "      <td>0.635116</td>\n",
       "      <td>0.595624</td>\n",
       "      <td>0.595624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ExtraTreeClassifier</td>\n",
       "      <td>0.920732</td>\n",
       "      <td>0.671398</td>\n",
       "      <td>0.601157</td>\n",
       "      <td>0.624464</td>\n",
       "      <td>0.601157</td>\n",
       "      <td>0.601157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ComplementNB</td>\n",
       "      <td>0.880081</td>\n",
       "      <td>0.605113</td>\n",
       "      <td>0.645233</td>\n",
       "      <td>0.620127</td>\n",
       "      <td>0.645233</td>\n",
       "      <td>0.645233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.922764</td>\n",
       "      <td>0.676409</td>\n",
       "      <td>0.589059</td>\n",
       "      <td>0.614229</td>\n",
       "      <td>0.589059</td>\n",
       "      <td>0.589059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>0.936992</td>\n",
       "      <td>0.885802</td>\n",
       "      <td>0.570334</td>\n",
       "      <td>0.605514</td>\n",
       "      <td>0.570334</td>\n",
       "      <td>0.570334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>RidgeClassifier</td>\n",
       "      <td>0.930894</td>\n",
       "      <td>0.746722</td>\n",
       "      <td>0.567052</td>\n",
       "      <td>0.595551</td>\n",
       "      <td>0.567052</td>\n",
       "      <td>0.567052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>RidgeClassifierCV</td>\n",
       "      <td>0.930894</td>\n",
       "      <td>0.746722</td>\n",
       "      <td>0.567052</td>\n",
       "      <td>0.595551</td>\n",
       "      <td>0.567052</td>\n",
       "      <td>0.567052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>0.760163</td>\n",
       "      <td>0.597732</td>\n",
       "      <td>0.804939</td>\n",
       "      <td>0.595338</td>\n",
       "      <td>0.804939</td>\n",
       "      <td>0.804939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>LogisticRegressionCV</td>\n",
       "      <td>0.914634</td>\n",
       "      <td>0.627239</td>\n",
       "      <td>0.571491</td>\n",
       "      <td>0.588530</td>\n",
       "      <td>0.571491</td>\n",
       "      <td>0.571491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>GaussianProcessClassifier</td>\n",
       "      <td>0.908537</td>\n",
       "      <td>0.605513</td>\n",
       "      <td>0.568209</td>\n",
       "      <td>0.580991</td>\n",
       "      <td>0.568209</td>\n",
       "      <td>0.568209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LinearDiscriminantAnalysis</td>\n",
       "      <td>0.908537</td>\n",
       "      <td>0.605513</td>\n",
       "      <td>0.568209</td>\n",
       "      <td>0.580991</td>\n",
       "      <td>0.568209</td>\n",
       "      <td>0.568209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>0.932927</td>\n",
       "      <td>0.801440</td>\n",
       "      <td>0.554955</td>\n",
       "      <td>0.580064</td>\n",
       "      <td>0.554955</td>\n",
       "      <td>0.554955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.918699</td>\n",
       "      <td>0.635220</td>\n",
       "      <td>0.560488</td>\n",
       "      <td>0.578587</td>\n",
       "      <td>0.560488</td>\n",
       "      <td>0.560488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>0.922764</td>\n",
       "      <td>0.649594</td>\n",
       "      <td>0.549484</td>\n",
       "      <td>0.566701</td>\n",
       "      <td>0.549484</td>\n",
       "      <td>0.549484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CalibratedClassifierCV</td>\n",
       "      <td>0.934959</td>\n",
       "      <td>0.967280</td>\n",
       "      <td>0.542857</td>\n",
       "      <td>0.562034</td>\n",
       "      <td>0.542857</td>\n",
       "      <td>0.542857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>0.934959</td>\n",
       "      <td>0.967280</td>\n",
       "      <td>0.542857</td>\n",
       "      <td>0.562034</td>\n",
       "      <td>0.542857</td>\n",
       "      <td>0.542857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>HistGradientBoostingClassifier</td>\n",
       "      <td>0.926829</td>\n",
       "      <td>0.681296</td>\n",
       "      <td>0.538481</td>\n",
       "      <td>0.552320</td>\n",
       "      <td>0.538481</td>\n",
       "      <td>0.538481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>0.920732</td>\n",
       "      <td>0.616805</td>\n",
       "      <td>0.535198</td>\n",
       "      <td>0.545900</td>\n",
       "      <td>0.535198</td>\n",
       "      <td>0.535198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.930894</td>\n",
       "      <td>0.965377</td>\n",
       "      <td>0.514286</td>\n",
       "      <td>0.509845</td>\n",
       "      <td>0.514286</td>\n",
       "      <td>0.514286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DummyClassifier</td>\n",
       "      <td>0.928862</td>\n",
       "      <td>0.464431</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.481560</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.928862</td>\n",
       "      <td>0.464431</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.481560</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.928862</td>\n",
       "      <td>0.464431</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.481560</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LabelPropagation</td>\n",
       "      <td>0.926829</td>\n",
       "      <td>0.464358</td>\n",
       "      <td>0.498906</td>\n",
       "      <td>0.481013</td>\n",
       "      <td>0.498906</td>\n",
       "      <td>0.498906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LabelSpreading</td>\n",
       "      <td>0.926829</td>\n",
       "      <td>0.464358</td>\n",
       "      <td>0.498906</td>\n",
       "      <td>0.481013</td>\n",
       "      <td>0.498906</td>\n",
       "      <td>0.498906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.922764</td>\n",
       "      <td>0.464213</td>\n",
       "      <td>0.496718</td>\n",
       "      <td>0.479915</td>\n",
       "      <td>0.496718</td>\n",
       "      <td>0.496718</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Model  Accuracy  Precision    Recall  F1-score  \\\n",
       "5           DecisionTreeClassifier  0.918699   0.682059  0.652829  0.665761   \n",
       "2                      BernoulliNB  0.847561   0.633567  0.812410  0.665443   \n",
       "1                BaggingClassifier  0.922764   0.694304  0.641826  0.662771   \n",
       "18              LogisticRegression  0.914634   0.658303  0.624258  0.638514   \n",
       "21                   MultinomialNB  0.894309   0.626664  0.652892  0.637969   \n",
       "23     PassiveAggressiveClassifier  0.920732   0.676886  0.614348  0.636859   \n",
       "26          RandomForestClassifier  0.934959   0.789076  0.595624  0.635116   \n",
       "7              ExtraTreeClassifier  0.920732   0.671398  0.601157  0.624464   \n",
       "4                     ComplementNB  0.880081   0.605113  0.645233  0.620127   \n",
       "0               AdaBoostClassifier  0.922764   0.676409  0.589059  0.614229   \n",
       "8             ExtraTreesClassifier  0.936992   0.885802  0.570334  0.605514   \n",
       "27                 RidgeClassifier  0.930894   0.746722  0.567052  0.595551   \n",
       "28               RidgeClassifierCV  0.930894   0.746722  0.567052  0.595551   \n",
       "22                 NearestCentroid  0.760163   0.597732  0.804939  0.595338   \n",
       "19            LogisticRegressionCV  0.914634   0.627239  0.571491  0.588530   \n",
       "10       GaussianProcessClassifier  0.908537   0.605513  0.568209  0.580991   \n",
       "16      LinearDiscriminantAnalysis  0.908537   0.605513  0.568209  0.580991   \n",
       "24                      Perceptron  0.932927   0.801440  0.554955  0.580064   \n",
       "11      GradientBoostingClassifier  0.918699   0.635220  0.560488  0.578587   \n",
       "25   QuadraticDiscriminantAnalysis  0.922764   0.649594  0.549484  0.566701   \n",
       "3           CalibratedClassifierCV  0.934959   0.967280  0.542857  0.562034   \n",
       "29                   SGDClassifier  0.934959   0.967280  0.542857  0.562034   \n",
       "12  HistGradientBoostingClassifier  0.926829   0.681296  0.538481  0.552320   \n",
       "17                       LinearSVC  0.920732   0.616805  0.535198  0.545900   \n",
       "13            KNeighborsClassifier  0.930894   0.965377  0.514286  0.509845   \n",
       "6                  DummyClassifier  0.928862   0.464431  0.500000  0.481560   \n",
       "9                       GaussianNB  0.928862   0.464431  0.500000  0.481560   \n",
       "30                             SVC  0.928862   0.464431  0.500000  0.481560   \n",
       "14                LabelPropagation  0.926829   0.464358  0.498906  0.481013   \n",
       "15                  LabelSpreading  0.926829   0.464358  0.498906  0.481013   \n",
       "20                   MLPClassifier  0.922764   0.464213  0.496718  0.479915   \n",
       "\n",
       "         AUC  Balanced Accuracy  \n",
       "5   0.652829           0.652829  \n",
       "2   0.812410           0.812410  \n",
       "1   0.641826           0.641826  \n",
       "18  0.624258           0.624258  \n",
       "21  0.652892           0.652892  \n",
       "23  0.614348           0.614348  \n",
       "26  0.595624           0.595624  \n",
       "7   0.601157           0.601157  \n",
       "4   0.645233           0.645233  \n",
       "0   0.589059           0.589059  \n",
       "8   0.570334           0.570334  \n",
       "27  0.567052           0.567052  \n",
       "28  0.567052           0.567052  \n",
       "22  0.804939           0.804939  \n",
       "19  0.571491           0.571491  \n",
       "10  0.568209           0.568209  \n",
       "16  0.568209           0.568209  \n",
       "24  0.554955           0.554955  \n",
       "11  0.560488           0.560488  \n",
       "25  0.549484           0.549484  \n",
       "3   0.542857           0.542857  \n",
       "29  0.542857           0.542857  \n",
       "12  0.538481           0.538481  \n",
       "17  0.535198           0.535198  \n",
       "13  0.514286           0.514286  \n",
       "6   0.500000           0.500000  \n",
       "9   0.500000           0.500000  \n",
       "30  0.500000           0.500000  \n",
       "14  0.498906           0.498906  \n",
       "15  0.498906           0.498906  \n",
       "20  0.496718           0.496718  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/bahramkhanbaloch/media3/MS/Semester1/DS/results/all_cities_random_shuffle.csv\n",
      "/home/bahramkhanbaloch/media3/MS/Semester1/DS/results/small_cities_test_city_Mainz_.csv\n",
      "/home/bahramkhanbaloch/media3/MS/Semester1/DS/results/small_cities_test_city_Trier_.csv\n",
      "/home/bahramkhanbaloch/media3/MS/Semester1/DS/results/big_cities_test_city_Munich_.csv\n",
      "/home/bahramkhanbaloch/media3/MS/Semester1/DS/results/big_cities_test_city_Berlin_.csv\n",
      "/home/bahramkhanbaloch/media3/MS/Semester1/DS/results/small_cities_test_city_SaarbrÃ¼cken_.csv\n",
      "/home/bahramkhanbaloch/media3/MS/Semester1/DS/results/big_cities_test_city_Stuttgart_.csv\n",
      "/home/bahramkhanbaloch/media3/MS/Semester1/DS/results/small_cities_test_city_Karlsruhe_.csv\n",
      "/home/bahramkhanbaloch/media3/MS/Semester1/DS/results/big_cities_test_city_Frankfurt_.csv\n",
      "                     Model  Average AUC\n",
      "1              BernoulliNB     0.784188\n",
      "13         NearestCentroid     0.767735\n",
      "8             ComplementNB     0.661513\n",
      "4            MultinomialNB     0.657249\n",
      "0   DecisionTreeClassifier     0.643120\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "# Get a list of all result files from different experiments\n",
    "result_files = glob.glob(\"/home/bahramkhanbaloch/media3/MS/Semester1/DS/results/*.csv\")\n",
    "\n",
    "# Create a dictionary to store the total AUC and count for each model\n",
    "auc_sum_per_model = {}\n",
    "count_per_model = {}\n",
    "\n",
    "# Iterate over each result file\n",
    "for file in result_files:\n",
    "    print(file)\n",
    "    # Load the results for each experiment\n",
    "    results = pd.read_csv(file)\n",
    "    \n",
    "    # Iterate over each row in the results\n",
    "    for _, row in results.iterrows():\n",
    "        model = row['Model']\n",
    "        auc = row['AUC']\n",
    "        \n",
    "        # Update the total AUC and count for the model\n",
    "        if model in auc_sum_per_model:\n",
    "            auc_sum_per_model[model] += auc\n",
    "            count_per_model[model] += 1\n",
    "        else:\n",
    "            auc_sum_per_model[model] = auc\n",
    "            count_per_model[model] = 1\n",
    "\n",
    "# Calculate the average AUC for each model\n",
    "average_auc_per_model = {model: auc_sum_per_model[model] / count_per_model[model] for model in auc_sum_per_model}\n",
    "\n",
    "# Create a DataFrame from the average AUC dictionary\n",
    "average_auc_df = pd.DataFrame(list(average_auc_per_model.items()), columns=['Model', 'Average AUC'])\n",
    "\n",
    "# Sort the DataFrame by Average AUC in descending order\n",
    "sorted_models = average_auc_df.sort_values(by='Average AUC', ascending=False)\n",
    "\n",
    "# Select the top 5 models\n",
    "top_5_models = sorted_models.head(5)\n",
    "\n",
    "# Display the best models\n",
    "print(top_5_models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BernoulliNB',\n",
       " 'NearestCentroid',\n",
       " 'ComplementNB',\n",
       " 'MultinomialNB',\n",
       " 'DecisionTreeClassifier']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_5_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  type_city  BernoulliNB  ComplementNB  DecisionTreeClassifier  MultinomialNB  \\\n",
      "0       big     0.764115      0.669090                0.621317       0.653853   \n",
      "1     small     0.810223      0.654498                0.681870       0.666221   \n",
      "2       all     0.810952      0.651410                0.672189       0.661778   \n",
      "\n",
      "   NearestCentroid  \n",
      "0         0.715620  \n",
      "1         0.853362  \n",
      "2         0.837221  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_386664/2782532669.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  combined_results = combined_results.append(results)\n",
      "/tmp/ipykernel_386664/2782532669.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  combined_results = combined_results.append(results)\n",
      "/tmp/ipykernel_386664/2782532669.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  combined_results = combined_results.append(results)\n",
      "/tmp/ipykernel_386664/2782532669.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  combined_results = combined_results.append(results)\n",
      "/tmp/ipykernel_386664/2782532669.py:44: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  summary_results = summary_results.append(row, ignore_index=True)\n",
      "/tmp/ipykernel_386664/2782532669.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  combined_results = combined_results.append(results)\n",
      "/tmp/ipykernel_386664/2782532669.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  combined_results = combined_results.append(results)\n",
      "/tmp/ipykernel_386664/2782532669.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  combined_results = combined_results.append(results)\n",
      "/tmp/ipykernel_386664/2782532669.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  combined_results = combined_results.append(results)\n",
      "/tmp/ipykernel_386664/2782532669.py:44: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  summary_results = summary_results.append(row, ignore_index=True)\n",
      "/tmp/ipykernel_386664/2782532669.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  combined_results = combined_results.append(results)\n",
      "/tmp/ipykernel_386664/2782532669.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  combined_results = combined_results.append(results)\n",
      "/tmp/ipykernel_386664/2782532669.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  combined_results = combined_results.append(results)\n",
      "/tmp/ipykernel_386664/2782532669.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  combined_results = combined_results.append(results)\n",
      "/tmp/ipykernel_386664/2782532669.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  combined_results = combined_results.append(results)\n",
      "/tmp/ipykernel_386664/2782532669.py:44: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  summary_results = summary_results.append(row, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "# Get a list of all result files from different experiments\n",
    "result_files = glob.glob(\"/home/bahramkhanbaloch/media3/MS/Semester1/DS/results/*.csv\")\n",
    "\n",
    "# Create an empty DataFrame to store the combined results\n",
    "combined_results = pd.DataFrame()\n",
    "\n",
    "# Create an empty DataFrame to store the summary\n",
    "summary_results = pd.DataFrame(columns=['type_city'])\n",
    "\n",
    "# Iterate over each result file\n",
    "for type_city in ['big', 'small', 'all']:\n",
    "    # Reset combined_results for each type_city iteration\n",
    "    combined_results = pd.DataFrame()\n",
    "\n",
    "    # Iterate over each result file\n",
    "    for file in result_files:\n",
    "        # Load the results for each experiment\n",
    "        if type_city in file:\n",
    "            results = pd.read_csv(file)\n",
    "            \n",
    "            # Append the results to the combined DataFrame\n",
    "            combined_results = combined_results.append(results)\n",
    "\n",
    "    # Calculate the average AUC for each model\n",
    "    average_auc_per_model = combined_results.groupby('Model')['AUC'].mean()\n",
    "    \n",
    "    # Sort the models by average AUC in descending order\n",
    "    sorted_models = average_auc_per_model.sort_values(ascending=False)\n",
    "    \n",
    "    # Filter the results to include only the rows corresponding to the top 5 models\n",
    "    filtered_results = combined_results[combined_results['Model'].isin(top_5_models)]\n",
    "\n",
    "    # Calculate the average AUC for each model\n",
    "    average_auc_by_model = filtered_results.groupby('Model')['AUC'].mean()\n",
    "    \n",
    "    # Create a row with type_city and average AUC values for each model\n",
    "    row = {'type_city': type_city}\n",
    "    row.update(average_auc_by_model)\n",
    "    \n",
    "    # Append the row to the summary_results DataFrame\n",
    "    summary_results = summary_results.append(row, ignore_index=True)\n",
    "\n",
    "# Display the summary_results DataFrame\n",
    "print(summary_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type_city</th>\n",
       "      <th>BernoulliNB</th>\n",
       "      <th>ComplementNB</th>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <th>MultinomialNB</th>\n",
       "      <th>NearestCentroid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>big</td>\n",
       "      <td>0.764115</td>\n",
       "      <td>0.669090</td>\n",
       "      <td>0.621317</td>\n",
       "      <td>0.653853</td>\n",
       "      <td>0.715620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>small</td>\n",
       "      <td>0.810223</td>\n",
       "      <td>0.654498</td>\n",
       "      <td>0.681870</td>\n",
       "      <td>0.666221</td>\n",
       "      <td>0.853362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>all</td>\n",
       "      <td>0.810952</td>\n",
       "      <td>0.651410</td>\n",
       "      <td>0.672189</td>\n",
       "      <td>0.661778</td>\n",
       "      <td>0.837221</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  type_city  BernoulliNB  ComplementNB  DecisionTreeClassifier  MultinomialNB  \\\n",
       "0       big     0.764115      0.669090                0.621317       0.653853   \n",
       "1     small     0.810223      0.654498                0.681870       0.666221   \n",
       "2       all     0.810952      0.651410                0.672189       0.661778   \n",
       "\n",
       "   NearestCentroid  \n",
       "0         0.715620  \n",
       "1         0.853362  \n",
       "2         0.837221  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_386664/1572437187.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  combined_results = combined_results.append(results)\n",
      "/tmp/ipykernel_386664/1572437187.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  combined_results = combined_results.append(results)\n",
      "/tmp/ipykernel_386664/1572437187.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  combined_results = combined_results.append(results)\n",
      "/tmp/ipykernel_386664/1572437187.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  combined_results = combined_results.append(results)\n",
      "/tmp/ipykernel_386664/1572437187.py:31: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  average_metrics_per_model = filtered_results.groupby('Model')['AUC', 'Accuracy', 'Precision', 'Recall'].mean()\n",
      "/tmp/ipykernel_386664/1572437187.py:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  summary_results = summary_results.append(row, ignore_index=True)\n",
      "/tmp/ipykernel_386664/1572437187.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  combined_results = combined_results.append(results)\n",
      "/tmp/ipykernel_386664/1572437187.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  combined_results = combined_results.append(results)\n",
      "/tmp/ipykernel_386664/1572437187.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  combined_results = combined_results.append(results)\n",
      "/tmp/ipykernel_386664/1572437187.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  combined_results = combined_results.append(results)\n",
      "/tmp/ipykernel_386664/1572437187.py:31: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  average_metrics_per_model = filtered_results.groupby('Model')['AUC', 'Accuracy', 'Precision', 'Recall'].mean()\n",
      "/tmp/ipykernel_386664/1572437187.py:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  summary_results = summary_results.append(row, ignore_index=True)\n",
      "/tmp/ipykernel_386664/1572437187.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  combined_results = combined_results.append(results)\n",
      "/tmp/ipykernel_386664/1572437187.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  combined_results = combined_results.append(results)\n",
      "/tmp/ipykernel_386664/1572437187.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  combined_results = combined_results.append(results)\n",
      "/tmp/ipykernel_386664/1572437187.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  combined_results = combined_results.append(results)\n",
      "/tmp/ipykernel_386664/1572437187.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  combined_results = combined_results.append(results)\n",
      "/tmp/ipykernel_386664/1572437187.py:31: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  average_metrics_per_model = filtered_results.groupby('Model')['AUC', 'Accuracy', 'Precision', 'Recall'].mean()\n",
      "/tmp/ipykernel_386664/1572437187.py:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  summary_results = summary_results.append(row, ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type_city</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>big</td>\n",
       "      <td>0.684799</td>\n",
       "      <td>0.813313</td>\n",
       "      <td>0.649200</td>\n",
       "      <td>0.684799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>small</td>\n",
       "      <td>0.733235</td>\n",
       "      <td>0.884658</td>\n",
       "      <td>0.617062</td>\n",
       "      <td>0.733235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>all</td>\n",
       "      <td>0.726710</td>\n",
       "      <td>0.876493</td>\n",
       "      <td>0.621050</td>\n",
       "      <td>0.726710</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  type_city       AUC  Accuracy  Precision    Recall\n",
       "0       big  0.684799  0.813313   0.649200  0.684799\n",
       "1     small  0.733235  0.884658   0.617062  0.733235\n",
       "2       all  0.726710  0.876493   0.621050  0.726710"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "# Get a list of all result files from different experiments\n",
    "result_files = glob.glob(\"/home/bahramkhanbaloch/media3/MS/Semester1/DS/results/*.csv\")\n",
    "\n",
    "# Create an empty DataFrame to store the combined results\n",
    "combined_results = pd.DataFrame()\n",
    "\n",
    "# Create an empty DataFrame to store the summary\n",
    "summary_results = pd.DataFrame(columns=['type_city', 'AUC', 'Accuracy', 'Precision', 'Recall'])\n",
    "\n",
    "# Iterate over each result file\n",
    "for type_city in ['big', 'small', 'all']:\n",
    "    # Reset combined_results for each type_city iteration\n",
    "    combined_results = pd.DataFrame()\n",
    "\n",
    "    # Iterate over each result file\n",
    "    for file in result_files:\n",
    "        # Load the results for each experiment\n",
    "        if type_city in file:\n",
    "            results = pd.read_csv(file)\n",
    "            \n",
    "            # Append the results to the combined DataFrame\n",
    "            combined_results = combined_results.append(results)\n",
    "\n",
    "    # Filter the results to include only the rows corresponding to the top 5 models\n",
    "    filtered_results = combined_results[combined_results['Model'].isin(top_5_models)]\n",
    "\n",
    "    # Calculate the average values for each metric\n",
    "    average_metrics_per_model = filtered_results.groupby('Model')['AUC', 'Accuracy', 'Precision', 'Recall'].mean()\n",
    "\n",
    "    # Calculate the average values for each metric\n",
    "    average_values = average_metrics_per_model.mean()\n",
    "\n",
    "    # Create a row with type_city, average values for each metric\n",
    "    row = {'type_city': type_city}\n",
    "    for metric in ['AUC', 'Accuracy', 'Precision', 'Recall']:\n",
    "        row[metric] = average_values[metric]\n",
    "\n",
    "    # Append the row to the summary_results DataFrame\n",
    "    summary_results = summary_results.append(row, ignore_index=True)\n",
    "\n",
    "# Display the summary_results DataFrame\n",
    "summary_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BernoulliNB',\n",
       " 'NearestCentroid',\n",
       " 'ComplementNB',\n",
       " 'MultinomialNB',\n",
       " 'DecisionTreeClassifier']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_5_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_results.to_csv(\"/home/bahramkhanbaloch/media3/MS/Semester1/DS/results/summary_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
